{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMofW9jyB8tNyrrWmtX/VwU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/epikadith/AI-model-creator-demo/blob/main/arch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "key = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "E5qBANoKsAfv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "from google import genai\n",
        "import tensorflow as tf\n",
        "from google.genai.errors import APIError\n",
        "\n",
        "def read_code_file(file_path: str) -> str:\n",
        "    if not os.path.exists(file_path):\n",
        "        return \"\"\n",
        "    with open(file_path, \"r\") as f:\n",
        "        return f.read()\n",
        "\n",
        "def write_code_file(file_path: str, content: str):\n",
        "    with open(file_path, \"w\") as f:\n",
        "        f.write(content)\n",
        "\n",
        "def get_dataset():\n",
        "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "    x_train = x_train[..., tf.newaxis]\n",
        "    x_test = x_test[..., tf.newaxis]\n",
        "    return x_train, y_train, x_test, y_test\n",
        "\n",
        "def run_real_training(code_content: str, model_name: str) -> dict:\n",
        "    x_train, y_train, x_test, y_test = get_dataset()\n",
        "\n",
        "    exec_globals = {}\n",
        "    try:\n",
        "        # Clean the code content by removing markdown fences if present\n",
        "        cleaned_code_content = code_content.strip()\n",
        "        if cleaned_code_content.startswith(\"```python\") and cleaned_code_content.endswith(\"```\"):\n",
        "            cleaned_code_content = cleaned_code_content[len(\"```python\"): -len(\"```\")].strip()\n",
        "        elif cleaned_code_content.startswith(\"```\") and cleaned_code_content.endswith(\"```\"):\n",
        "            cleaned_code_content = cleaned_code_content[len(\"```\"): -len(\"```\")].strip()\n",
        "\n",
        "        exec(cleaned_code_content, exec_globals)\n",
        "        MyModel = exec_globals['MyModel']\n",
        "        model = MyModel()\n",
        "    except Exception as e:\n",
        "        print(f\"Error instantiating model: {e}\")\n",
        "        return {\"loss\": 99.0, \"accuracy\": 0.0, \"error\": str(e), \"code_generated\": code_content}\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    print(f\"🛠️ Training model: {model_name}...\")\n",
        "    try:\n",
        "        model.fit(x_train, y_train, epochs=1, verbose=2)\n",
        "        print(f\"📊 Evaluating model: {model_name}...\")\n",
        "        results = model.evaluate(x_test, y_test, verbose=2)\n",
        "        return {\n",
        "            \"loss\": round(results[0], 4),\n",
        "            \"accuracy\": round(results[1], 4),\n",
        "            \"params\": model.count_params(),\n",
        "            \"code_generated\": code_content\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Error during training or evaluation: {e}\")\n",
        "        return {\"loss\": 99.0, \"accuracy\": 0.0, \"error\": str(e), \"code_generated\": code_content}\n",
        "\n",
        "\n",
        "def get_llm_response(client: genai.Client, prompt: str, model_name: str) -> str:\n",
        "    print(f\"Calling LLM with prompt: {prompt[:100]}...\")\n",
        "    try:\n",
        "        response = client.models.generate_content(model=model_name, contents=prompt)\n",
        "        return response.text\n",
        "    except APIError as e:\n",
        "        print(f\"An API error occurred: {e}\")\n",
        "        return \"Error: Could not generate a response from the LLM.\"\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "        return \"Error: Could not generate a response from the LLM.\"\n",
        "\n",
        "class Researcher:\n",
        "    def __init__(self, client: genai.Client):\n",
        "        self.client = client\n",
        "        self.base_prompt = \"\"\"\n",
        "        You are an AI architect. Your task is to design a Python class for a neural network model.\n",
        "        The model should be a simple classifier using Keras/TensorFlow.\n",
        "\n",
        "        IMPORTANT: You MUST output ONLY the Python code for the class, enclosed in triple backticks (```python).\n",
        "        The class name must be 'MyModel'. Ensure the code is syntactically correct and runnable.\n",
        "\n",
        "        Current model code: {current_code}\n",
        "        Analysis of past experiments: {analysis}\n",
        "\n",
        "        Based on the analysis (especially any error messages), design a new or corrected architecture.\n",
        "        If there was an error, your primary goal is to fix that error in the new code.\n",
        "\n",
        "        Example model structure:\n",
        "        ```python\n",
        "        import tensorflow as tf\n",
        "\n",
        "        class MyModel(tf.keras.Model):\n",
        "            def __init__(self):\n",
        "                super().__init__()\n",
        "                self.flatten = tf.keras.layers.Flatten()\n",
        "                self.dense1 = tf.keras.layers.Dense(128, activation='relu')\n",
        "                self.dense2 = tf.keras.layers.Dense(10, activation='softmax')\n",
        "\n",
        "            def call(self, inputs):\n",
        "                x = self.flatten(inputs)\n",
        "                x = self.dense1(x)\n",
        "                return self.dense2(x)\n",
        "        ```\n",
        "        \"\"\"\n",
        "\n",
        "    def propose_new_architecture(self, context: dict) -> str:\n",
        "        analysis = context.get(\"analysis\", \"No previous analysis available.\")\n",
        "        current_code = context.get(\"parent_code\", self.get_initial_code())\n",
        "\n",
        "        full_prompt = self.base_prompt.format(current_code=current_code, analysis=analysis)\n",
        "        new_code = get_llm_response(self.client, full_prompt, model_name=\"gemini-2.5-pro\")\n",
        "        return new_code\n",
        "\n",
        "    def get_initial_code(self) -> str:\n",
        "        return \"\"\"\n",
        "import tensorflow as tf\n",
        "\n",
        "class MyModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1))\n",
        "        self.pool1 = tf.keras.layers.MaxPooling2D((2, 2))\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "\n",
        "        self.dense1 = tf.keras.layers.Dense(64, activation='relu')\n",
        "        self.dense2 = tf.keras.layers.Dense(10, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.pool1(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.dense1(x)\n",
        "        return self.dense2(x)\n",
        "\"\"\"\n",
        "\n",
        "class Engineer:\n",
        "    def __init__(self, client: genai.Client):\n",
        "        self.client = client\n",
        "\n",
        "    def train_and_evaluate(self, code_content: str, model_name: str) -> dict:\n",
        "        return run_real_training(code_content, model_name)\n",
        "\n",
        "class Analyst:\n",
        "    def __init__(self, client: genai.Client):\n",
        "        self.client = client\n",
        "        self.base_prompt = \"\"\"\n",
        "        You are a seasoned AI researcher. Analyze the following model's performance and code.\n",
        "\n",
        "        Model code: {code_content}\n",
        "        Performance metrics: {metrics}\n",
        "\n",
        "        IMPORTANT: If the metrics contain an 'error' key, your primary task is to analyze that error.\n",
        "        Provide concrete, line-by-line suggestions for fixing the code, clearly pointing out the problematic parts.\n",
        "        Your analysis should be directly actionable for the Researcher to generate corrected code.\n",
        "\n",
        "        If there's no error, provide an insightful summary of the model's strengths and weaknesses,\n",
        "        and suggest concrete architectural changes for the next iteration to improve performance (e.g., add more layers, change activation, etc.).\n",
        "        \"\"\"\n",
        "\n",
        "    def analyze_results(self, code_content: str, metrics: dict) -> str:\n",
        "        prompt = self.base_prompt.format(code_content=code_content, metrics=json.dumps(metrics, indent=2))\n",
        "        analysis = get_llm_response(self.client, prompt, model_name=\"gemini-2.5-flash\")\n",
        "        return analysis\n",
        "\n",
        "def main(api_key: str):\n",
        "    client = genai.Client(api_key=api_key)\n",
        "\n",
        "    researcher = Researcher(client)\n",
        "    engineer = Engineer(client)\n",
        "    analyst = Analyst(client)\n",
        "\n",
        "    database = []\n",
        "    current_context = {}\n",
        "\n",
        "    for i in range(3):\n",
        "        print(f\"\\n--- 🚀 Starting Iteration {i+1} ---\")\n",
        "\n",
        "        print(\"💡 Researcher is proposing a new architecture...\")\n",
        "        new_code = researcher.propose_new_architecture(current_context)\n",
        "        model_name = f\"model_iter_{i+1}\"\n",
        "        file_path = f\"{model_name}.py\"\n",
        "\n",
        "        write_code_file(file_path, new_code)\n",
        "\n",
        "        print(\"⚙️ Engineer is training the model...\")\n",
        "        performance_metrics = engineer.train_and_evaluate(new_code, model_name)\n",
        "\n",
        "        print(\"📊 Analyst is evaluating the results...\")\n",
        "        analysis_report = analyst.analyze_results(new_code, performance_metrics)\n",
        "\n",
        "        experiment = {\n",
        "            \"id\": i + 1,\n",
        "            \"name\": model_name,\n",
        "            \"code\": new_code,\n",
        "            \"metrics\": performance_metrics,\n",
        "            \"analysis\": analysis_report\n",
        "        }\n",
        "        database.append(experiment)\n",
        "\n",
        "        current_context[\"analysis\"] = analysis_report\n",
        "        current_context[\"parent_code\"] = new_code\n",
        "\n",
        "        print(f\"\\n✅ Iteration {i+1} complete. Metrics: {performance_metrics}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    key = key\n",
        "    main(key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYH1oU6eF1oV",
        "outputId": "97231892-8550-411f-a67c-004f8d37add3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 🚀 Starting Iteration 1 ---\n",
            "💡 Researcher is proposing a new architecture...\n",
            "Calling LLM with prompt: \n",
            "        You are an AI architect. Your task is to design a Python class for a neural network model.\n",
            "...\n",
            "⚙️ Engineer is training the model...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "🛠️ Training model: model_iter_1...\n",
            "1875/1875 - 26s - 14ms/step - accuracy: 0.9508 - loss: 0.1656\n",
            "📊 Evaluating model: model_iter_1...\n",
            "313/313 - 2s - 6ms/step - accuracy: 0.9809 - loss: 0.0615\n",
            "📊 Analyst is evaluating the results...\n",
            "Calling LLM with prompt: \n",
            "        You are a seasoned AI researcher. Analyze the following model's performance and code.\n",
            "     ...\n",
            "\n",
            "✅ Iteration 1 complete. Metrics: {'loss': 0.0615, 'accuracy': 0.9809, 'params': 347146, 'code_generated': \"```python\\nimport tensorflow as tf\\n\\nclass MyModel(tf.keras.Model):\\n    def __init__(self):\\n        super().__init__()\\n        # The 'input_shape' argument is removed from the first layer.\\n        # In a subclassed model, the input shape is inferred automatically\\n        # the first time the model is called with actual data.\\n        # Specifying it here can cause errors and is not the standard practice.\\n        self.conv1 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')\\n        self.pool1 = tf.keras.layers.MaxPooling2D((2, 2))\\n        self.flatten = tf.keras.layers.Flatten()\\n    \\n        self.dense1 = tf.keras.layers.Dense(64, activation='relu')\\n        self.dense2 = tf.keras.layers.Dense(10, activation='softmax')\\n        \\n    def call(self, inputs):\\n        x = self.conv1(inputs)\\n        x = self.pool1(x)\\n        x = self.flatten(x)\\n        x = self.dense1(x)\\n        return self.dense2(x)\\n```\"}\n",
            "\n",
            "--- 🚀 Starting Iteration 2 ---\n",
            "💡 Researcher is proposing a new architecture...\n",
            "Calling LLM with prompt: \n",
            "        You are an AI architect. Your task is to design a Python class for a neural network model.\n",
            "...\n",
            "⚙️ Engineer is training the model...\n",
            "🛠️ Training model: model_iter_2...\n",
            "1875/1875 - 63s - 33ms/step - accuracy: 0.9195 - loss: 0.2674\n",
            "📊 Evaluating model: model_iter_2...\n",
            "313/313 - 3s - 8ms/step - accuracy: 0.9860 - loss: 0.0468\n",
            "📊 Analyst is evaluating the results...\n",
            "Calling LLM with prompt: \n",
            "        You are a seasoned AI researcher. Analyze the following model's performance and code.\n",
            "     ...\n",
            "\n",
            "✅ Iteration 2 complete. Metrics: {'loss': 0.0468, 'accuracy': 0.986, 'params': 122314, 'code_generated': \"```python\\nimport tensorflow as tf\\n\\nclass MyModel(tf.keras.Model):\\n    def __init__(self):\\n        super().__init__()\\n        # First convolutional block with Batch Normalization\\n        self.conv1 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')\\n        self.bn1 = tf.keras.layers.BatchNormalization()\\n        self.pool1 = tf.keras.layers.MaxPooling2D((2, 2))\\n\\n        # Second convolutional block (deeper architecture)\\n        self.conv2 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')\\n        self.bn2 = tf.keras.layers.BatchNormalization()\\n        self.pool2 = tf.keras.layers.MaxPooling2D((2, 2))\\n\\n        # Flatten and Dense layers with Dropout for regularization\\n        self.flatten = tf.keras.layers.Flatten()\\n        self.dense1 = tf.keras.layers.Dense(64, activation='relu')\\n        self.dropout = tf.keras.layers.Dropout(0.5) # Increased dropout for regularization\\n        self.dense2 = tf.keras.layers.Dense(10, activation='softmax')\\n        \\n    def call(self, inputs, training=False):\\n        # Forward pass for the first block\\n        x = self.conv1(inputs)\\n        x = self.bn1(x, training=training)\\n        x = self.pool1(x)\\n\\n        # Forward pass for the second block\\n        x = self.conv2(x)\\n        x = self.bn2(x, training=training)\\n        x = self.pool2(x)\\n\\n        # Classification head\\n        x = self.flatten(x)\\n        x = self.dense1(x)\\n        x = self.dropout(x, training=training)\\n        return self.dense2(x)\\n```\"}\n",
            "\n",
            "--- 🚀 Starting Iteration 3 ---\n",
            "💡 Researcher is proposing a new architecture...\n",
            "Calling LLM with prompt: \n",
            "        You are an AI architect. Your task is to design a Python class for a neural network model.\n",
            "...\n",
            "⚙️ Engineer is training the model...\n",
            "🛠️ Training model: model_iter_3...\n",
            "1875/1875 - 108s - 58ms/step - accuracy: 0.9505 - loss: 0.1758\n",
            "📊 Evaluating model: model_iter_3...\n",
            "313/313 - 5s - 16ms/step - accuracy: 0.9851 - loss: 0.0432\n",
            "📊 Analyst is evaluating the results...\n",
            "Calling LLM with prompt: \n",
            "        You are a seasoned AI researcher. Analyze the following model's performance and code.\n",
            "     ...\n",
            "\n",
            "✅ Iteration 3 complete. Metrics: {'loss': 0.0432, 'accuracy': 0.9851, 'params': 111370, 'code_generated': \"```python\\nimport tensorflow as tf\\n\\nclass MyModel(tf.keras.Model):\\n    def __init__(self):\\n        super().__init__()\\n        # First convolutional block\\n        self.conv1 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')\\n        self.bn1 = tf.keras.layers.BatchNormalization()\\n        self.pool1 = tf.keras.layers.MaxPooling2D((2, 2))\\n\\n        # Second convolutional block\\n        self.conv2 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')\\n        self.bn2 = tf.keras.layers.BatchNormalization()\\n        self.pool2 = tf.keras.layers.MaxPooling2D((2, 2))\\n\\n        # Third convolutional block for increased depth and feature extraction\\n        self.conv3 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')\\n        self.bn3 = tf.keras.layers.BatchNormalization()\\n        \\n        # Replace Flatten with GlobalAveragePooling2D for regularization and efficiency\\n        self.global_pool = tf.keras.layers.GlobalAveragePooling2D()\\n        \\n        # Dense classification head\\n        self.dense1 = tf.keras.layers.Dense(128, activation='relu')\\n        self.dropout = tf.keras.layers.Dropout(0.5)\\n        self.dense2 = tf.keras.layers.Dense(10, activation='softmax')\\n        \\n    def call(self, inputs, training=False):\\n        # Forward pass for the first block\\n        x = self.conv1(inputs)\\n        x = self.bn1(x, training=training)\\n        x = self.pool1(x)\\n\\n        # Forward pass for the second block\\n        x = self.conv2(x)\\n        x = self.bn2(x, training=training)\\n        x = self.pool2(x)\\n\\n        # Forward pass for the new third block\\n        x = self.conv3(x)\\n        x = self.bn3(x, training=training)\\n\\n        # Use Global Average Pooling\\n        x = self.global_pool(x)\\n\\n        # Classification head\\n        x = self.dense1(x)\\n        x = self.dropout(x, training=training)\\n        return self.dense2(x)\\n```\"}\n"
          ]
        }
      ]
    }
  ]
}